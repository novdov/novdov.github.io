<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-02-14T11:23:06+09:00</updated><id>http://localhost:4000/</id><title type="html">novdov’s blog</title><author><name>Sunwoong Kim</name></author><entry><title type="html">tf.estimator 사용하기 - 01. tf.data와 tf.record를 이용해 데이터 읽고 저장하기</title><link href="http://localhost:4000/tensorflow/deep%20learning/2019/02/13/tf.Estimator-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-01-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A7%8C%EB%93%A4%EA%B8%B0/" rel="alternate" type="text/html" title="tf.estimator 사용하기 - 01. tf.data와 tf.record를 이용해 데이터 읽고 저장하기" /><published>2019-02-14T06:00:00+09:00</published><updated>2019-02-14T06:00:00+09:00</updated><id>http://localhost:4000/tensorflow/deep%20learning/2019/02/13/tf.Estimator-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-01-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A7%8C%EB%93%A4%EA%B8%B0</id><content type="html" xml:base="http://localhost:4000/tensorflow/deep%20learning/2019/02/13/tf.Estimator-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-01-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A7%8C%EB%93%A4%EA%B8%B0/">&lt;h2 id=&quot;tfestimator-와-효과적인-data-사용&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.estimator&lt;/code&gt; 와 효과적인 Data 사용&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.estimator&lt;/code&gt; 는 Tensorflow의 High-level API로 평가, 학습, 예측과 서빙을 위한 모델 저장등을 편하게 수행할 수 있게 해줍니다. Estimators 를 사용하면서 (Estimator 외에도) Tensorflow 에서 데이터를 효과적으로 사용하기 위해서는 데이터를 여러 개의 직렬화된 데이터에 나눠 저장해 이용하는 것이 좋습니다. Tensorflow 에서는 TFRecord 를 통해 데이터를 직렬화하고 읽을 수 있습니다. 데이터를 직렬화하고 TFRecord 형식으로 저장하고 이를 읽기 위해 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.Example&lt;/code&gt; 을 이용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;여기서는 먼저 &lt;code class=&quot;highlighter-rouge&quot;&gt;.txt&lt;/code&gt; 형식의 파일을 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.data.TextLineDataset&lt;/code&gt; 을 이용해 읽어 오고, &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.Example&lt;/code&gt; 로 데이터를 직렬화한 뒤, TFRecord 형식으로 다시 저장하는 과정을 진행해봅니다.&lt;/p&gt;

&lt;h2 id=&quot;데이터-읽고-파싱하기&quot;&gt;데이터 읽고 파싱하기&lt;/h2&gt;

&lt;p&gt;먼저 일반적인 &lt;code class=&quot;highlighter-rouge&quot;&gt;.txt&lt;/code&gt; 형식의 파일을 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.data.TextLineDataset&lt;/code&gt; 으로 읽어오겠습니다. 예제 데이터로 NSMC (Naver Sentiment Movie Corpus) 를 이용합니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.data&lt;/code&gt; 로 데이터를 읽는 것은 간단합니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.data&lt;/code&gt; (여기서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.data.TextLineDataset&lt;/code&gt;) 을 선언하고 한 번에 읽ㅇ어 올 배치 사이즈를 지정한 다음, iterator 를 생성합니다. 구체적인 코드는 아래와 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;FEATURE_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;review&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hparams&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batchsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;iterate_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Read text file with tf.data.TextLineDataset.
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_decode_tsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parsed_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;null&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_delim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parsed_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;feature&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parsed_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FEATURE_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TextLineDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;skip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_decode_tsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hparams&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_one_shot_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Iterator 를 리턴하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;iterate_data(filename)&lt;/code&gt; 함수를 정의합니다. 이 함수는 내부에서 텍스트 파일 한 라인을 파싱할 &lt;code class=&quot;highlighter-rouge&quot;&gt;_decode_tsv(line)&lt;/code&gt; 을 매핑합니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.decode_csv(records, record_defaults)&lt;/code&gt; 의 &lt;code class=&quot;highlighter-rouge&quot;&gt;record_defaults&lt;/code&gt; 는 한 라인 각 요소의 데이터 타입을 예시로 지정해줍니다. NSMC 데이터는 각 라인이 &lt;code class=&quot;highlighter-rouge&quot;&gt;\t&lt;/code&gt; 으로 분리되어 있고, 각 원소는 id (int), 리뷰 (string), sentiment (int) 로 이루어져 있습니다. 이를 위해 &lt;code class=&quot;highlighter-rouge&quot;&gt;record_defaults&lt;/code&gt; 를 &lt;code class=&quot;highlighter-rouge&quot;&gt;[[0], [&quot;null&quot;], [0]]&lt;/code&gt; 으로 지정해 주었습니다. 한편, decode 함수는 (feature Dict, label) 튜플을 리턴합니다.&lt;/p&gt;

&lt;p&gt;이후 위의 함수를 이용해서 데이터를 불러오는 코드는 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterate_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRAIN_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;next_elem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_elem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;데이터를 불러오면 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;batch_features&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'review'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\xea\xb5\xb3&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\xe3\x85\x8b&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;batch_labels&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.data&lt;/code&gt; 로 데이터를 불러오면 텍스트는 utf-8로 인코딩 된 상태입니다. 우리가 읽을 수 있고, 여러 가지 전처리를 하기 위해서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;str.decode(&quot;utf-8&quot;)&lt;/code&gt; 로 디코딩 해줍니다. (Tensorflow 1.3 에서는 unicode 인코딩/디코딩 API가 제공됩니다.)&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;batch_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;review&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;'굳 ㅋ'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;위에서는 예시로 들기 위해 첫 번째 배치만 얻고 반복문을 중지했지만 실제로는 &lt;code class=&quot;highlighter-rouge&quot;&gt;while&lt;/code&gt; 문으로 데이터를 끝까지 불러옵니다. 유의할 점은, 데이터를 불러오는 &lt;code class=&quot;highlighter-rouge&quot;&gt;.get_next()&lt;/code&gt; 를 반복문 안이 아니라 밖에서 선언한다는 점입니다. 실제로는 아래와 같은 형태로 데이터를 읽습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;            
            &lt;span class=&quot;n&quot;&gt;batch_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_elem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OutOfRangeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;tfexample-로-example-만들기&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.Example&lt;/code&gt; 로 Example 만들기&lt;/h2&gt;

&lt;p&gt;그럼 데이터를 읽어올 수 있으니, TFRecord로 다시 저장하기 위해 Example 을 만들어 줍니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.Example&lt;/code&gt; 을 이용합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;데이터 만들기&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;데이터 저장&lt;/li&gt;
  &lt;li&gt;tf.record 불러오기
    &lt;ul&gt;
      &lt;li&gt;tf.data.TfRecordDataset&lt;/li&gt;
      &lt;li&gt;tf.python_io.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Sunwoong Kim</name></author><category term="deep learning" /><category term="tensorflow" /><summary type="html">tf.estimator 와 효과적인 Data 사용</summary></entry><entry><title type="html">[Review] You May Not Need Attention</title><link href="http://localhost:4000/nlp/deep%20learning/2018/11/16/You-May-Not-Need-Attention/" rel="alternate" type="text/html" title="[Review] You May Not Need Attention" /><published>2018-11-16T18:23:00+09:00</published><updated>2018-11-16T18:23:00+09:00</updated><id>http://localhost:4000/nlp/deep%20learning/2018/11/16/You-May-Not-Need-Attention</id><content type="html" xml:base="http://localhost:4000/nlp/deep%20learning/2018/11/16/You-May-Not-Need-Attention/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;최근 활발히 연구되고 있는 NMT 모델은 다음의 속성을 따른다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Decoder는 source sequence representation에 대해 attention을 사용한다.&lt;/li&gt;
  &lt;li&gt;Encoder와 Decoder는 두 개의 다른 모듈이며, Encoder는 Decoder의 작동 전에 source sentence의 encoding을 마쳐야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;논문에서는 NMT 모델이 위의 속성 없이 얼마나 성능을 낼 수 있는지 확인한다. 논문은 기존의 Encoder-Decoder with attention 모델과 다른 구조로 NMT를 실험했고, 이 모델을 &lt;strong&gt;eager translation model&lt;/strong&gt;이라고 부른다.&lt;/p&gt;

&lt;p&gt;이를 위해 논문에서는 Bahdanau et al. (2014)의 모델로 시작해 attention을 제거하고 Encoder와 Decoder를 하나의 간단한 모델로 합친다. 이 모델은 Zaremba et al. (2014)의 langaugae model을 닮았다. 이를 통해 논문의 모델은 source word가 입력되지마자 번역을 시작할 수 있다. Eager translation model은 일정 개수의 메모리만 사용하는데 이는 매 타임 스텝마다 직전 타임 스텝의 히든 스테이트만 이용하기 때문이다. 한편, 논문의 모델이 다른 모델과 가장 큰 차이점을 보이는 곳은 preprocessing이다.&lt;/p&gt;

&lt;h2 id=&quot;data-preprocessing&quot;&gt;Data Preprocessing&lt;/h2&gt;

&lt;p&gt;논문에서 소개하는 preprocessing의 핵심은 source/target 문장의 &lt;strong&gt;align&lt;/strong&gt; (정렬)이다. 논문에서는 이를 위해 source/target sentence에 특정 속성을 요구한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;source/target 문장의 대응 관계를 inferring 하는데, 이 때 각 target 단어는 최대 하나의 source 단어에 매칭된다. 그리고 정렬된 $(s_i, \boldsymbol{t}_j)$ 쌍이 $i \le j$ 를 만족하는 상태를 &lt;em&gt;eager feasible&lt;/em&gt; 하다고 부른다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;논문에서는 위의 속성을 만족시키기 위해 먼저 off-the-shelf 모델 (&lt;code class=&quot;highlighter-rouge&quot;&gt;fast_align&lt;/code&gt;; &lt;a href=&quot;http://www.aclweb.org/anthology/N13-1073&quot;&gt;Dyer at el., 2013&lt;/a&gt;) 을 사용해 source/target 문장 간의 대응을 예측한 뒤 최소한의 $\epsilon$ (empty) 토큰을 target 문장에 삽입한다. 이 $\epsilon$ 토큰은 학습과 예측 단계에서만 사용되고 실제 번역 문장을 만들어낼 때에는 제거된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fast_align&lt;/code&gt; 모델은 source/target 문장 간 대응의 maximum likelihood를 log-linear 속도로 찾아내는 간단하고 빠른 모델이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;예를 들어 source 문장 “El perro blanco” (“The dog white”)의 올바른 번역은 “The white dog.”이다. 영어 문장의 두 번째 단어 (white)와 스페인 문장의 세 번째 단어가 분명하게 대응 (정렬)된다는 것을 가정하면 시퀀스를 eager feasible하게 만들기 위해 논문의 모델은 target 문장을 “The $\epsilon$ white dog.” 으로 변환한다.&lt;/p&gt;

&lt;p&gt;논문에서 소개하는 eager feasible 알고리즘은 아래와 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;source 문장을 $s = \langle s_1, \ldots, s_m \rangle$ , target 문장을 $\boldsymbol{t} = \langle t_1, \ldots, t_n \rangle$ 이라고 했을 때 $\mathcal{A}$ 를 정렬 쌍 $(i, j)$ 의 집합으로 둔다. ($t_j$ 가 $s_i$ 에 대응된다.)&lt;/li&gt;
  &lt;li&gt;target 문장을 왼쪽에서 오른쪽으로 살펴본다. 현재 target 단어가 $t$ 이고 현재의 위치는 $j$ 로 가정한다. $t$ 가 source 단어 $s_i$ 와 정렬되고 (에 대응하고) $i \le j$ 이면 다음 target 단어로 넘어간다. (정렬된 상태이므로)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;그렇지 않을 경우 해당 target 단어 바로 앞에 $\epsilon$ 토큰을 삽입한다. 토큰 삽입으로 $t$ 는 target 문장에서 $i$ 위치로 이동한다. 물론, 다른 target 단어들도 오른쪽으로 이동한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;또한 위의 작업을 조금 더 간단하게 하기 위해 논문에서는 모든 target 문장 앞에 $b \in { 0, 1, \ldots, 5 }$ 개의 $\epsilon$ 토큰을 미리 더한 뒤 실험했다. 이는 모델이 번역 전에 더 많은 source 문장을 소비하도록 한다. 즉 예측 시에 모델이 $b$ 개의 $\epsilon$ 을 번역 전에 만들어내도록 강제한다. 논문의 모델은 문장 앞의 $\epsilon$ 도 고려함으로써 target 문장 사이에 삽입해야 할 $\epsilon$ 의 개수를 줄인다.&lt;/li&gt;
  &lt;li&gt;위의 과정 후에 source/target 문장의 길이가 동일하지 않을 경우 짧은 문장 뒤에 $\epsilon$ 을 추가해 두 문장의 길이를 맞춘다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;model&quot;&gt;Model&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;매 타임 스텝마다 모델은 source 언어의 현재 입력 단어와 target 언어의 출력 단어를 각각 $E$ 차원으로 임베딩한다.   이 두 벡터는 $2E$ 차원으로 concat 된 뒤, multi-layer LSTM에 입력된다. LSTM의 출력은 FC layer를 이용해 $E$ 차원으로 변환된다. 이 벡터는 출력 임베딩과 softmax 를 이용해 target 사전의 distribution으로 변환된다. 모델은 또한 source 언어의 입력 임베딩, target 언어의 입력 임베딩, 출력 임베딩을 공유한다.&lt;/li&gt;
  &lt;li&gt;논문에서 소개하는 모델은 Zaremba et al. (2014)의 recurrent language model과 매우 닮아 있다. 모델에서처럼, 논문에서도 teacher forcing과 cross-entropy loss를 사용한다. padding 심볼도 target sentence의 한 부분으로 다뤄졌고, 이를 위한 별도의 loss나 objective funtion은 사용되지 않았다.&lt;/li&gt;
  &lt;li&gt;또한 다른 번역 모델과 달리 논문의 모델은 inference 중에 일정 양의 메모리만 사용한다. 메모리에 직전 히든 스테이트만 저장하고 인코딩된 이전 단어들의 representation은 저장하지 않는다. 이를 통해 decoding complexity는 최악의 경우 $\mathscr{O}(n+m)$ 이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;aligned-batching&quot;&gt;Aligned Batching&lt;/h3&gt;

&lt;p&gt;preprocessing 이후에 모든 source-target 쌍은 동일한 길이로 변한다. 논문에서는 이 다음 source 문장과 target 문장을 각각 순서를 유지한 string으로 합친다. 이를 통해 모델은 마치 language model을 학습하는 것처럼 학습할 수 있다. 구체적으로는 BPTT 하이퍼파라미터가 지정된다. 각 배치의 모든 요소는 BPTT source 토큰과 각각에 대응하는 target 토큰을 포함한다. language model을 학습할 때처럼, ($i-1$) 번째 배치의 마지막 히든 스테이트가 $i$ 번재 배치의 첫 히든 스테이트가 된다.&lt;/p&gt;

&lt;h3 id=&quot;decoding&quot;&gt;Decoding&lt;/h3&gt;

&lt;p&gt;논문에서는 예측 (inference) 중에 출력의 질을 향상시키기 위해 beam search를 조정해 사용한다. 구체적인 조정은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Padding limit: 논문에서는 $\epsilon$ 의 개수가 제한 개수에 다다르면 $\epsilon$ 의 등장 확률을 0으로 강제함으로써 패딩 토큰의 최대 개수에 제한을 두었다. 처음에 삽입되는 패딩 토큰은 이 제한 개수에 포함되지 않는다.&lt;/li&gt;
  &lt;li&gt;Source padding injection (SPI): 논문에서는 decoder가 source 언어의 EOS 토큰을 읽으면 이 EOS 토큰에 높은 확률을 부여한다는 것을 발견했다. 이에 논문에서는 SPI 파라미터를 $c$ 로 두었고, beam search에서는 0부터 $c$ 까지는 EOS 전까지를 $\epsilon$ 으로 간주한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;h3 id=&quot;setup&quot;&gt;Setup&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;실험은 EN ⟷ FR, EN ⟷ DE 로 이루어졌고, 학습/검증/테스트 데이터는 각각 WMT 2014, newstest2013, newstest2014를 이용했다. 각 문장은 토크나이징과 30,000 BPE opeartion을 거친다.&lt;/li&gt;
  &lt;li&gt;네트워크의 구조는 먼저 4개의 LSTM 레이어 (1,000 units, embedding 500dim)를 이용한다. 학습 중 레이어와 임베딩에는 droutput이 적용된다. 배치 사이즈는 200, unroll step은 60이다. SGD를 사용했고, 첫 learning rate는 20이다. 논문에서는 6,500 스텝마다 검증 데이터에 대한 perplexity를 확인하고, 개선이 없으면 learning rate를 1/2로 줄인다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/f4HmYkX.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;eager 모델은 EN ⟷ FR에 대해서는 레퍼런스 모델보다 최대 0.8% 낮은 BLEU를 보였다. 그러나 EN ⟷ DE 에서는 최대 4.8% 레퍼런스보다 낮은 성능을 보였다.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/k5O8rvO.png&quot; alt=&quot;Imgur&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;문장 길이로 모델의 성능을 확인했을 때는 긴 문장에서는 eager 모델이 더 좋은 성능을 보였으나 짧은 문장에 대해서는 레퍼런스 모델보다 낮은 성능을 보였다. 이는 attention 기반의 방법이 짧은 문장 학습에 어려움을 보이기 떄문이다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;논문에서 소개한 방법은 토크나이징 결과와, source/target 문장 간의 어순, 닮음새에 영향을 많이 받을 것으로 보인다. 특히 한국어/영어 같이 문장의 서술 구조의 차이가 큰 경우에는 align이 쉽지 않을 뿐더러, 높은 성능을 기대하기도 어려울 것 같다.&lt;/li&gt;
  &lt;li&gt;다만 기존 NMT의 Encoder-Decoder 구조를 이용하지 않더라도 기존과 비슷한 성능을 보인다는 것은 모델의 구조 뿐만 아니라, 데이터 전처리 방법이 얼마나 중요한지 보여주는 대목이라고 생각된다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Sunwoong Kim</name></author><category term="nlp" /><category term="deep learning" /><category term="review" /><summary type="html">Introduction</summary></entry><entry><title type="html">[Review] Universal Transformers</title><link href="http://localhost:4000/nlp/deep%20learning/2018/09/27/Review-Universal_Transformers/" rel="alternate" type="text/html" title="[Review] Universal Transformers" /><published>2018-09-27T18:23:00+09:00</published><updated>2018-09-27T18:23:00+09:00</updated><id>http://localhost:4000/nlp/deep%20learning/2018/09/27/Review-Universal_Transformers</id><content type="html" xml:base="http://localhost:4000/nlp/deep%20learning/2018/09/27/Review-Universal_Transformers/">&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1807.03819&quot;&gt;Mostafa Dehghani et al., Universal Transformers., 2018&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;해당 코드: https://github.com/tensorflow/tensor2tensor&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Transformer 모델 같은 convolutional &amp;amp; fully-attentional feed-forward 아키텍처는 최근, MT와 같은 시퀀스 모델링에서 RNN의 대체제로 떠올랐다. Transformer 모델은 self-attention 메커니즘을 통해 입출력 심볼의 context-informed vector-space representation을 학습한다. 이 representation은 모델이 symbol-by-symol로 출력 시퀀스를 예측하기 때문에, 서브시퀀트 심볼의 분산을 예측한다. Transformer 모델의 이러한 점은 병렬화하기 쉽고, 각 심볼의 representaion이 다른 심볼의 representaion에 의해 직접적인 정보를 담기 때문에, 효과적인 receptive field를 얻을 수 있다는 이점을 가져온다.&lt;/li&gt;
  &lt;li&gt;Transformer 모델은 반복적이고 재귀적인 transformation을 학습하는 RNN의 inductive bias에 앞서지만, 이 inductive bias가 언어의 복잡성을 학습하는데 중요한 역할을 한다는 것을 실험 결과가 보여준다. 이 때문에 Transformer는 계산적으로 일반화하기 매우 어렵다. Universal Transformer는 이러한 단점들을 극복한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/Fc9cipx.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model&quot;&gt;Model&lt;/h2&gt;

&lt;h3 id=&quot;the-universal-transformer&quot;&gt;The Universal Transformer&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/zAP064b.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Universal Transformer는 sequence-to-sequence 모델에서 흔히 쓰이는 encoder-decoder 구조에 기반한다.  그러나 Universal Transformer는 시퀀스 위치를 순환하지 않고, 각 위치의 vector representaion의 연속적인 갱신(revision)을 순환한다는 점에서 기존의 RNN과 가장 큰 차이를 가진다. &lt;strong&gt;즉 Universal Transformer는 시퀀스 내의 심볼 개수에 구애받지 않고, 각 심볼의 representaion의 업데이트 횟수에 귀속된다.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;매 스텝마다 각 위치에서의 representation은 2단계에 걸쳐 갱신된다.
    &lt;ul&gt;
      &lt;li&gt;먼저, Universal Transformer는 self-attention 메커니즘을 사용해 모든 위치에서 정보를 교환하고 각 위치의 representation을 생성한다. 이 representation은 이전 타임 스텝의 representation에 영향을 받는다.&lt;/li&gt;
      &lt;li&gt;그 다음, 각 위치에서 독립적으로 self-attention 출력값에 &lt;em&gt;shared&lt;/em&gt; transition을 적용한다. 이 점이 레이어를 쌓는 Transformer나 RNN 등 유명한 neural 시퀀스 모델과 가장 차별되는 점이다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{Attention}(Q, K, V) = \text{softmax}(\dfrac{QK^T}{\sqrt(d)})V \\
\text{MultiHeadSelfAttention}(H) = \text{Concat}(\text{head}_1, \ldots, \text{head}_k)W^O \\
\text{where head}_i = \text{Attention}(HW_i^Q, HW_i^K, HW_i^V)&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Encoder로는 $m$ 길이의 입력이 주어졌을 때, $d$ 차원의 임베딩으로 초기화된 행렬을 이용한다. ($H^0 \in \mathbb{R}^{m \times d}$) Universal Transformer는 그 다음 반복해서 $t$ 스텝에서의 $m$ 위치의 represantation $H^t$을 계산하는데, 이 때 multiheaded dot-product self-attention, recurrent transition을 적용한다. residual connection과 dropout, layer normalization 또한 함께 적용된다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;작업에 따라 transition은 separable convolution이나 fully-connected NN (with relu) 중 하나가 사용된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$T$ 스텝 이후에 Universal Transformer의 최종 출력값은 입력 시퀀스의 $m$ 심볼의 $d$ 차원 representation 행렬이다. ($H^T \in \mathbb{R}^{m \times d}$)&lt;/li&gt;
  &lt;li&gt;Decoder는 기본적으로 encoder와 동일한 구조를 가진다. 하지만, decoder는 self-attention 이후에 decoder represention에서 얻은 쿼리 $Q$ 와 encoder representation을 projection해서 얻은 key/value $K, V$ 를 이용해 입력 시퀀스 각 위치의 최종 encoder representation $H^T$ 으로 향하는 attention을 추가로 계산한다.&lt;/li&gt;
  &lt;li&gt;학습 동안 Decoder  입력은 encoder-decoder 구조와 동일하게 오른쪽으로 하나의 위치만큼 이동한 목표 출력이다.&lt;/li&gt;
  &lt;li&gt;마지막으로 목표 심볼 distribution은 최종 decoder state에서 출력 사전 크기 $V$ 로 affine 변환 $O \in \mathbb{R}^{d \times V}$ 과 softmax를 통해 얻어진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y_{pos} \vert y_{[1:pos-1]}, H^T) = \text{softmax}(OH^T)^1&lt;/script&gt;

&lt;h3 id=&quot;the-adaptive-universal-transformer&quot;&gt;The Adaptive Universal Transformer&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;시퀀스 프로세싱 중에, 특정 심볼들은 다른 것들보다 모호할 때가 있어 이 심볼들을 처리하는 데 자원을 더 쏟는 것이 필요하다. 이 때 각 심볼에 필요한 계산량을 조절하는 ACT (Adaptive Computation Time)을 Universal Transformer에 적용한 것을  The Adaptive Universal Transformer라고 부른다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;논문에서는 총 6가지 태스크를 통해 Universal Transformer를 평가했다. 6가지 태스크는 아래와 같다.
    &lt;ul&gt;
      &lt;li&gt;bAbI Question-Answering&lt;/li&gt;
      &lt;li&gt;Subject-Verb Agreement&lt;/li&gt;
      &lt;li&gt;LAMBADA Language Modeling&lt;/li&gt;
      &lt;li&gt;Algorithmic Tasks&lt;/li&gt;
      &lt;li&gt;Learning to Execute (LTE)&lt;/li&gt;
      &lt;li&gt;Machine Translation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;babi-question-answering&quot;&gt;bAbI Question-Answering&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;bAbI Question-Answering 데이터셋은 주어진 영어 문장에서 supporting facts를 인코딩하는 질문에 답하는 20가지의 태스크로 이루어져 있다.&lt;/li&gt;
  &lt;li&gt;Adaptive Universal Transformer가 10K/1K 모두에서 SOTA 성능을 보였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/9vMSNMB.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;subject-verb-agreement&quot;&gt;Subject-Verb Agreement&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;subject와 verb 일치를 평가하는 태스크로, hierarchical (dependency) 구조를 얼마나 잘 잡아내는 지 확인하는 태스크이다.&lt;/li&gt;
  &lt;li&gt;Universal Transformer는 기존의 Transformer보다 나은 성능을 보였고, Adaptive Universal Transformer는 SOTA와 견줄만한 성능을 보였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/UivpQHy.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;lambada-language-modeling&quot;&gt;LAMBADA Language Modeling&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;LAMBADA Language Modeling 태스크는 주어진 문장을 통해 공백 단어를 예측하는 문제이다.&lt;/li&gt;
  &lt;li&gt;해당 태스크에서도 Universal Transformer가 SOTA 성능을 이뤄냈다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/3uH0c6I.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;algorithmic-tasks&quot;&gt;Algorithmic Tasks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Universal Transformer가 LSTM과 Transformer보다 나은 성능을 보였다.&lt;/li&gt;
  &lt;li&gt;Neural GPU가 완벽한 결과를 보이지만, 이는 특별한 과정이 추가되었기 때문이며, 다른 모델은 그렇지 않다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/nz9QN9a.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;learning-to-execute-lte&quot;&gt;Learning to Execute (LTE)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;이 태스크는 컴퓨터 프로그램을 실행하도록 학습할 수 있는지 평가하는 문제이다.&lt;/li&gt;
  &lt;li&gt;Universal Transformer는 모든 태스크에서 완벽한 결과를 보였다.
    &lt;ul&gt;
      &lt;li&gt;위: char-acc (maximum length of 55)&lt;/li&gt;
      &lt;li&gt;아래: char-acc (maximum nesting of 2 nad length of 5)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/NYneV7H.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/loFRg0Y.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;machine-translation&quot;&gt;Machine Translation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;MT 태스크는 WMT 2014 영어-독일어로 평가되었다.&lt;/li&gt;
  &lt;li&gt;Universal Transformer (with fully-connected recurrent function without ACT) 가 기본 Transformer보다 BLEU를 0.9 향상시켰다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/NH8fGw1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;universality-and-relationship-to-other-models&quot;&gt;Universality and Relationship to Other Models&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Universal Transformer는 end-to-end Memory Network와도 관련되어 있다. 그러나 end-to-end Memory Network와는 다르게 Universal Transformer는 개별 입/출력 위치에 정렬된 스테이트에 해당하는 메모리를 사용한다. 또한, Universal Transformer는 encoder-decoder 구조를 따르며 대규모 sequence-to-sequence 태스크에서 좋은 성능을 보인다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Universal Transformer는 다음의 주요 속성을 하나의 모델에 결합했다.
    &lt;ul&gt;
      &lt;li&gt;Weight sharing
        &lt;ul&gt;
          &lt;li&gt;CNN/RNN에서 사용되는 weight sharing을 도입해 소규모/대규모 태스크에서 inductive bias와 모델의 표현력 사이에서 경쟁력 있는 능력을 갖췄다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Conditional Computation
        &lt;ul&gt;
          &lt;li&gt;Universal Transformer는 ACT를 도입해 fixed-depth Universal Transformer보다 더 강력한 능력을 갖췄다. (The Adaptive Universal Transformer)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;appendix&quot;&gt;Appendix&lt;/h2&gt;

&lt;h3 id=&quot;detailed-schema-of-the-universal-transformer&quot;&gt;Detailed Schema of the Universal Transformer&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/aX52RnY.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Sunwoong Kim</name></author><category term="nlp" /><category term="deep learning" /><category term="review" /><summary type="html">Mostafa Dehghani et al., Universal Transformers., 2018 해당 코드: https://github.com/tensorflow/tensor2tensor</summary></entry><entry><title type="html">[Review] Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm</title><link href="http://localhost:4000/deeplearning/nlp/2018/08/26/Review-Using-millions-of-emoji-occurrences-to-learn-any-domain-representations-for-detecting-sentiment,-emotion-and-sarcasm.md/" rel="alternate" type="text/html" title="[Review] Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm" /><published>2018-08-26T00:00:00+09:00</published><updated>2018-08-26T00:00:00+09:00</updated><id>http://localhost:4000/deeplearning/nlp/2018/08/26/Review-Using-millions-of-emoji-occurrences-to-learn-any-domain-representations-for-detecting-sentiment,-emotion-and-sarcasm.md</id><content type="html" xml:base="http://localhost:4000/deeplearning/nlp/2018/08/26/Review-Using-millions-of-emoji-occurrences-to-learn-any-domain-representations-for-detecting-sentiment,-emotion-and-sarcasm.md/">&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1708.00524&quot;&gt;Bjarke Felbo, Alan Mislove, Anders Søgaard, Iyad Rahwan, Sune Lehmann. 2017. Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm. ACL 2017, pages 1615–1625&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;레이블링 된 데이터의 부족으로 NLP 작업이 제한되는 경우가 있다. 이런 이유로 문장에 나타나는 감정 표현은 소셜 미디어 감성 분석과 연관 작업에서 representation을 학습하는 데에 유용하게 사용되고 있다.&lt;/li&gt;
  &lt;li&gt;이를 이용한 State-of-the-art 접근법으로는 소셜 미디어 감성 분석에 긍정/부정 이모티콘을 사용했고 (Deriu et al., 2016; Tang et al., 2014), 이와 비슷하게 #anger, #joy 같은 해시태그를 사용해 감정 분석에 접근한 방법도 있다. (Mohammad, 2012)&lt;/li&gt;
  &lt;li&gt;노이즈가 섞인 레이블을 이용한 Distant supervision은 많은 경우에 모델의 성능을 향상시킨다. 본 논문에서는 더 다양한 노이즈가 섞인 레이블로 Distant supervision을 확장하고, 이러한 시도가 텍스트에서 더 풍부한 감정 representation 학습을 가능케 했다. (DeepMoji) 본 논문에서는 단일 pretrained model을 5가지 도메인으로 일반화한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;

&lt;h3 id=&quot;pretraining&quot;&gt;Pretraining&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;논문은 많은 경우에 이모지가 텍스트의 감정 정보를 시사하는 사실을 바탕으로, 이모지를 예측하는 분류 모델을 미리 학습하는 것이 목표 작업의 성능을 향상시키다고 말한다.&lt;/li&gt;
  &lt;li&gt;데이터로는 2013.01.01~ 2017.06.01 간의 트윗을 사용했으나, 이모지가 포함된 텍스트라면 상관 없다. 한편, URL이 포함된 트윗은 해당 URL이 감정 표현의 대상이 된다고 가정하고 URL이 없는 트윗만 사용되었다.&lt;/li&gt;
  &lt;li&gt;토크나이징은 단어 기준으로 진행되었고, 중복된 토큰은 정규화되었다. (‘loool’ = ‘looooool’) URL (벤치마크 데이터셋)과 숫자도 마찬가지로 정규화되었다.&lt;/li&gt;
  &lt;li&gt;이모지에 대해서는, 사용된 이모지의 개수와 상관없이 같은 종류의 이모지면 pretraining을 위한 데이터로 사용되었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;model&quot;&gt;Model&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;DeepMoji 모델 구성은 다음과 같다.
    &lt;ul&gt;
      &lt;li&gt;Embedding (256 dim) &amp;amp; tanh (L2 regularization of 1E-6)&lt;/li&gt;
      &lt;li&gt;2 bi-LSTM (1024 dim, 512 dim each)&lt;/li&gt;
      &lt;li&gt;Attention layer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/112C7M6.png?1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;transfer-learning&quot;&gt;Transfer Learning&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;pretrain 된 모델은 transfer learning을 통해 목적 작업에 적용될 수 있는데, 본 논문에서는 “chain-thaw”라는 간단한 접근법을 소개한다. “chain-thaw” 방법은 순차적으로 가중치를 고정하고, 한번에 하나의 레이어만 업데이트하는 방법이다.&lt;/li&gt;
  &lt;li&gt;구체적으로는 먼저 어느 한 레이어를 학습시키고, (보통 Softmax 레이어) 그 다음 첫 번째 레이어부터 순차적으로 업데이트한다. 마지막에는 모든 레이어가 업데이트된다.&lt;/li&gt;
  &lt;li&gt;chain-thaw을 통해 오버피팅의 리스크를 줄이면서 어휘를 새로운 도메인으로 확장할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/jZfN6DA.png?1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;h3 id=&quot;emoji-prediction&quot;&gt;Emoji prediction&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;pretraining 데이터에서 트윗은 하나의 이모지에 대응하도록 복사되었고, 이렇게 준비된 데이터는 트윗 16억 개이다. validation/test 데이터로는 각각 640K 개 (각 이모지 당 10K 개)가 사용되었다. 나머지 트윗은 모두 upsampling을 거쳐 학습 데이터로 사용되었다.&lt;/li&gt;
  &lt;li&gt;DeepMoji 모델은 pretraining task로 평가되었고, 결과는 아래의 표와 같다. top 1과 top 5 정확도 모두 노이즈가 섞인 이모지 레이블로 평가되었다. (어떤 문장에도 적합한 이모지 등)&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Params&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Top 1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Top 5&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Random&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.6%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;7.8%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;fasttext (d = 256)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;12.8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;12.8%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;36.2%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DeepMoji (d = 512)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;15.5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;16.7%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;43.3%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DeepMoji (d = 1024)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;22.4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;17.0%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;43.8%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;fastText만 사용한 모델은 DeepMoji의 임베딩 레이어만 사용한 것과 동일한 결과를 냈다. 한편, fastText와 DeepMoji의 Top 5 정확도 차이는 이모지 예측의 어려움을 보여준다.&lt;/li&gt;
  &lt;li&gt;DeepMoji는 임베딩과 Softmax 레이어 사이에 어텐션 레이어가 있는 LSTM 레이어를 가지는데, 이 차이가 각 단어의 context를 잡아내는 데 중요한 역할을 했다고 말해준다.&lt;/li&gt;
  &lt;li&gt;요즘의 모델들은 기본적으로 biLSTM과 어텐션 레이어 등을 포함하는데, (biLSTM은 거의 기본값이 된 듯 한다.) 이것은 그만큼 biLSTM과 어텐션의 성능이 NLP 작업에서 뛰어나다는 것을 보여준다고 생각한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;benchmarking&quot;&gt;Benchmarking&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;논문에서는 5개 도메인의 8개 데이터를 이용해 3개의 NLP 작업을 수행해 모델의 벤치마크 성능을 평가했다.&lt;/li&gt;
  &lt;li&gt;평가 metric으로는 감정 분석과 sarcasm에는 F1이, 감성 분류에는 정확도가 사용되었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/EtJLLUw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;벤치마킹 결과는 chain-thaw 방법을 활용한 DeepMoji 모델은 state-of-the-art 모델보다 모든 데이터셋에서 더 높은 성능을 보였다. 벤치마킹 결과는 DeepMoji의 좋은 성능에는 chain-thaw 영향이 크다는 것을 말해준다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;model-analysis&quot;&gt;Model Analysis&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;DeepMoji와 이전의 distant supervison 방법들의 가장 큰 차이는 DeepMoji는 노이즈가 섞인 레이블을 다양하게 활용했다는 점이다. 다양한 이모지의 영향을 알아보기 위해 1/8로 줄인 이모지 데이터셋 (긍/부정)을 활용한 결과, 벤치마크 상의 성능은 데이터의 크기보다 레이블의 다양성과 더 연관이 있었다.&lt;/li&gt;
  &lt;li&gt;이모지는 비슷한 감정을 나타내지만, 문맥마다 미묘한 차이를 나타낸다. DeepMoji는 이러한 미묘함을 학습했고, 이는 성능 향상으로 이어졌다는 것이다.&lt;/li&gt;
  &lt;li&gt;transfer learning 성능 향상에 대해 논문은 이렇게 추측한다. 1) skip connections를 적용한 어텐션 메커니즘 덕분에 모델이 어느 time step에서도 low-level features에 쉽게 접근해서 새로운 작업에 이용할 수 있다는 점, 2) 작은 데이터셋으로의 transfer learning에서 skip connections 덕분에 출력 레이어에서 초기 레이어로의 gradient 흐름이 개선된 점&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;이 논문은 이모지를 이용해 감정 정보를 학습했고, 개선된 transfer learning으로 NLP 작업에서의 성능을 개선했다. DeepMoji 모델 또한 감정이라는 context를 학습한 contextualized embedding이라고도 볼 수 있을 것 같다.&lt;/li&gt;
  &lt;li&gt;또한 살펴볼 것은, 2-layer BiLSTM과 어텐션 메커니즘, skip connections의 사용이다. 최근 소개되는 state-of-the-art 모델들은 거의 대부분 어텐션 메커니즘이 추가된 BiLSTM을 이용하고 있다. 그만큼 NLP 작업에서 BiLSTM과 어텐션 메커니즘의 성능이 뛰어나다는 것일 것이다.&lt;/li&gt;
  &lt;li&gt;다만, 이러한 큰 네트워크를 학습하기 위해서는 그만큼 풍부한 데이터도 중요하다고 생각한다. State-of-the-art contextualized embedding인 ELMo의 경우에도 4096 차원의 아주 큰 BiLSTM과 1B token dataset을 이용한 BIG-CNN-LSTM (char-CNN, 2048 filteres)을 이용한다. 결국 context 학습이 최종 목적이 아니라, 이 모델을 다른 작업에 transfer learning으로 적용하자고 하는 것이기 때문에 더더욱 그럴 것이라고 생각한다. CV 분야에서도 미리 학습된 VGG 등을 이용해 transfer learning을 적용하는 것과 궤를 같이 한다고 생각한다.&lt;/li&gt;
  &lt;li&gt;그러나 여기서 한국어 NLP에 적용하기 위한 한계점도 있는데, 영어권 자료에 비해 대규모 한국어 데이터셋은 공개된 것이 많이 부족하다는 것이다. 세종 코퍼스는 2000년대 초반에 종료된 프로젝트이며, 그 양도 많지 않아 아쉬울 뿐이다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Sunwoong Kim</name></author><category term="[&quot;DeepLearning&quot;, &quot;NLP&quot;]" /><category term="nlp" /><category term="deep learning" /><summary type="html">Bjarke Felbo, Alan Mislove, Anders Søgaard, Iyad Rahwan, Sune Lehmann. 2017. Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm. ACL 2017, pages 1615–1625</summary></entry><entry><title type="html">[프로세스와 스레드] 01. 프로세스와 스레드</title><link href="http://localhost:4000/python/2018/08/12/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C-01-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C/" rel="alternate" type="text/html" title="[프로세스와 스레드] 01. 프로세스와 스레드" /><published>2018-08-12T00:00:00+09:00</published><updated>2018-08-12T00:00:00+09:00</updated><id>http://localhost:4000/python/2018/08/12/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C-01-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C</id><content type="html" xml:base="http://localhost:4000/python/2018/08/12/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C-01-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C/">&lt;blockquote&gt;
  &lt;p&gt;출처: 컴퓨터 사이언스 부트캠프 with 파이썬 (양태환, 길벗)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;멀티프로세스와 멀티스레드를 자주 사용하게 되었는데, 프로세스/스레드의 개념과 파이썬의 멀티프로세싱/멀티스레딩의 차이를 알아봅니다. 이미지와 글의 출처는 참고로 명시한 책에서 가져왔습니다.&lt;/p&gt;

&lt;h2 id=&quot;1-프로세스&quot;&gt;1. 프로세스&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;프로그램: 하드디스크에 저장된 실행 파일. 실행하지 않는 이상 하드디스크에 계속 남아 있으며, 같은 경로에 같은 이름으로 동시에 존재할 수는 없다.&lt;/li&gt;
  &lt;li&gt;프로세스: 프로그램을 실행한 상태. 하드디스크에서 메인 메모리로 코드와 데이터를 가져와 현재 실행되고 있는 상태. 프로세스는 동시에 여러 개가 존재할 수 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;11-프로세스-상태&quot;&gt;1.1 프로세스 상태&lt;/h3&gt;

&lt;p&gt;프로세스를 실행하려면 독자적인 메모리 공간과 CPU가 필요하다. 메모리는 가상 메모리를 사용해서 해결한다. CPU는 한번에 하나의 프로세스에만 할당할 수 있다. 여러 프로세스가 완벽하게 ‘동시에’ 실행되는 건 불가능하다. 프로세스 상태는 상황에 따라 변한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;생성 (Created): 프로그램을 더블클릭했을 때 프로세스가 생성되면서 실행 가능 상태가 된다. 바로 실행되는 것이 아니라, 우선 실행 가능 상태가 되어 실행 중인 프로세스와 우선순위를 비교한 다음 실행하거나 순서를 기다린다.&lt;/li&gt;
  &lt;li&gt;실행 가능 (Waiting): 실행 가능 상태의 프로세스는 언제든지 실행할 준비가 되어 있다. 운영체제는 인터럽트가 발생했을 때 실행 가능 상태의 프로세스 중 다음으로 CPU를 할당받아 실행될 프로세스에 CPU를 할당받아 실행될 프로세스에 결정한 후, 실행 중인 프로세스와 교체한다. 이 때 다음으로 실행될 프로세스에 CPU를 할당하는 것을 디스패치(dispatch)라고 하고, 실행 중이던 프로세스에서 CPU를 해제하는 것을 프리엠션(preemption)이라고 한다.&lt;/li&gt;
  &lt;li&gt;실행 (Running): 프로세스가 운영체제로부터 CPU를 할당받아 실행되고 있는 상태&lt;/li&gt;
  &lt;li&gt;보류 (Blocked): 프로세스가 I/O 작업을 하면 CPU를 해제하고 보류 상태로 변경된다. 이 때 실행 가능 상태의 프로세스 중 하나가 CPU를 할당받는다. I/O 작업이 완료된 다음 바로 실행 가능 상태로 변경되는 것이 아니라, 실행 가능 상태가 되어 실행되기를 기다린다. 또 Waiting는 언제든지 다시 실행될 수 있는 상태를 말하지만, 보류 상태는 I/O 작업이 끝나기 전에는 실행이 불가능한 상태이다.&lt;/li&gt;
  &lt;li&gt;소멸 (Terminated): 프로세스 실행이 완료되어 메인 메로리에서 사라진다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;12-스케줄링&quot;&gt;1.2 스케줄링&lt;/h3&gt;

&lt;p&gt;스케줄링(scheduling)이란 운영체제가 여러 프로세스의 CPU 할당 순서를 결정하는 것이다. 이 일을 하는 프로그램을 스케줄러라고 한다.&lt;/p&gt;

&lt;p&gt;스케줄링은 CPU를 언제 할당하는지에 따라 선점형 스케줄링(preemptive scheduling)과 비선점형 스케줄링(non-preemptive scheduling)으로 나눌 수 있다.&lt;/p&gt;

&lt;p&gt;선점형 스케줄링에서는 어떤 프로세스가 실행 중에 있어도 스케줄러가 강제로 실행을 중지하고 다른 프로세스에 CPU를 할당할 수 있다. 비선점형 스케줄링에서는 실행 중인 프로세스가 종료되거나 I/O 작업에 들어가거나 명시적으로 CPU를 반환하기 전까지는 계속해서 실행된다. 우선순위가 높은 프로세스가 생성되어도 실행 중인 프로세스가 자발적으로 CPU를 양보하기 전까지는 실행될 수 없다.&lt;/p&gt;

&lt;h3 id=&quot;13-컨텍스트-스위칭&quot;&gt;1.3 컨텍스트 스위칭&lt;/h3&gt;

&lt;p&gt;프로세스 두 개가 같은 프로그램에서 만들어졌을 때 두 프로세스는 독립된 메모리 공간을 가진다. 프로세스가 실행되려면 다양한 CPU 레지스터 값과 프로세스 상태 정보 등이 필요하다. 그러므로 프로세스가 실행 상태에서 실행 가능 상태로 변경될 때 이러한 정보를 메모리 어딘가에 저장해야 한다. 프로세스의 CPU 상태와 프로세스의 상태를 저장해 둔 메모리 블록을 프로세스 제어 블록(Process Control Block, PCB)이라고 한다.&lt;/p&gt;

&lt;p&gt;스케줄러가 실행 중인 프로세스에서 CPU를 해제하고 실행 가능 상태의 프로세스에 CPU를 할당할 때, 실행 중인 프로세스의 CPU 상태 정보를 그 프로세스의 PCBdp 저장하고 곧 실행될 프로세스의 PCB에서 이전 CPU 상태 정보를 CPU로 가져오는 것을 컨텍스트 스위칭(context switching)이라고 한다. CPU 상태를 컨텍스트라고 부르는데 말 그대로 현재 CPU의 레지스터 값들을 전환하는 것이다.&lt;/p&gt;

&lt;h2 id=&quot;2-스레드&quot;&gt;2. 스레드&lt;/h2&gt;

&lt;p&gt;스레드(thread)란 프로세스 안의 실행 흐름의 단위로 스케줄러에 의해 CPU를 할당받을 수 있는 인스트럭션의 나열이다. 프로세스는 하나 이상의 스레드로 구성된다.&lt;/p&gt;

&lt;p&gt;프로세스가 PCB를 갖는 것처럼 스레드는 스레드 제어 블록(Thread Control Bock, TCB)을 갖는다. TCB에는 스레드 ID, 각종 레지스터 정보, 스레드 상태 정보, 스레드가 속해 있는 프로세스의 TCB 주소 등이 저장되어 있다.&lt;/p&gt;

&lt;p&gt;프로세스와 스레드 모두 인스트럭션의 나열이고 유사한 정보가 든 메모리 블록을 갖는다. 프로세스가 단일 스레드로 작동하면 프로세스와 스레드는 차이가 없다. 프로세스와 스레드의 차이점을 알려면 멀티프로세스와 멀티스레드를 비교해야 한다.&lt;/p&gt;

&lt;h3 id=&quot;21-멀티프로세스와-멀티스레드&quot;&gt;2.1 멀티프로세스와 멀티스레드&lt;/h3&gt;

&lt;p&gt;단일 코어 CPU에서 여러 개의 실행 흐름이 동시에 필요하다고 가정하면, 실행 흐름사이에서 데이터를 공유해야 한다. 실행 흐름은 결국 CPU를 점유하고 인스트럭션을 실행하는 것을 말하므로 여러 실행 흐름을 구현하려면 멀티프로세스나 멀티스레드로 구현해야 한다.&lt;/p&gt;

&lt;p&gt;먼저 멀티프로세스로 구현한다고 가정하면, 프로세스는 서로 독립적인 메모리 공간을 가지므로 기본적으로 데이터를 공유할 수 없다. 멀티프로세스에서는 모든 프로세스가 서로 다른 메로리 공간을 가지므로 데이터를 공유하려면 특별한 기법을 사용해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/HwWeXWT.png&quot; alt=&quot;멀티프로세스의 메모리 구조&quot; /&gt;&lt;/p&gt;

&lt;p&gt;하지만 멀티스레드로 구현하면 데이터를 쉽게 공유할 수 있다. 멀티프로세스와 달리 여러 스레드가 스택만 서로 다른 공간을 갖고, 코드, 데이터, 힙은 공유하기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ifxbRza.png&quot; alt=&quot;멀티스레드의 메모리 구조&quot; /&gt;&lt;/p&gt;

&lt;p&gt;스레드는 각자 독립적인 스택 세그먼트를 갖지만, 코드, 데이터, 힙은 다른 스레드와 공유한다. 데이터 세그멘트나 힙 세그먼트에 공유 데이터를 두면 모든 스레드가 이용할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;li&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;아래 예는 위의 싱글 스레드 작업을 멀티 스레딩으로 바꾼 코드이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;threading&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;thread_main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;num_elem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_thread&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_elem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_thread&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;li&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_elem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threading&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thread_main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                          &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;26&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;36&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;38&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;44&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;46&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;48&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;52&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;56&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;58&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;62&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;66&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;68&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;72&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;74&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;76&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;78&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;82&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;84&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;86&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;88&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;92&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;94&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;96&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;98&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;102&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;104&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;106&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;108&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;110&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;112&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;114&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;116&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;118&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;122&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;124&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;126&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;130&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;132&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;134&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;136&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;138&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;140&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;142&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;144&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;146&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;148&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;152&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;154&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;156&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;158&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;160&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;162&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;164&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;166&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;168&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;170&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;172&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;174&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;176&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;178&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;180&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;182&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;184&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;186&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;188&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;190&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;192&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;194&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;196&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;198&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;23-경쟁-조건&quot;&gt;2.3 경쟁 조건&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;threading&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;g_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;thread_main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;global&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g_count&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;g_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        
&lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threading&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thread_main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'g_count: {:,}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;902&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;146&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;전역 변수 &lt;code class=&quot;highlighter-rouge&quot;&gt;g_count&lt;/code&gt;를 선언하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;thread_main()&lt;/code&gt; 함수 안에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;g_count&lt;/code&gt; 값에 1을 100,000번 더한다.
스레드를 총 50개 만들었으니 스레드 50개가 동시에 &lt;code class=&quot;highlighter-rouge&quot;&gt;g_count&lt;/code&gt;에 접근해 값을 수정하려고 시도한다. 이처럼 여러 스레드가 동시에 접근, 수정, 공유 가능한 자원을 공유 자원이라고 한다. 위 코드에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;g_count&lt;/code&gt;라는 전역 변수가 공유 자원이다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;g_count&lt;/code&gt;의 최종 값은 스레드가 각각 100,000번 씩 값을 증가시키므로 5,000,000이 될 것 같지만, 실행 결과는 매번 달라진다.&lt;/p&gt;

&lt;p&gt;이상적인 경우에서는 먼저 전역 변수 &lt;code class=&quot;highlighter-rouge&quot;&gt;g_count&lt;/code&gt; 값을 범용 레지스터로 가져와 값을 증가시키고, 연산이 끝난 레지스터 값을 &lt;code class=&quot;highlighter-rouge&quot;&gt;g_count&lt;/code&gt;에 저장한다. 이제 컨텍스트 스위칭이 일어나 스레드 2에 CPU가 할당된다. 이 과정이 반복되는 것이 이상적인 경우이지만 선점형 스케줄링에서는 스레드 1의 연산이 완전히 끝날 때까지 컨텍스트 스위칭을 기다려 주지 않는다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;g_count&lt;/code&gt;에 값을 저장하기 전에 컨텍스트 스위칭이 일어나면 다른 스레드가 이전 레지스터 값을 복원하고 이전 상태에 이어 연산을 마무리한다. 각 스레드의 관점에서 보면 스레드는 첫 번째 경우나 두 번째 경우 모두 &lt;code class=&quot;highlighter-rouge&quot;&gt;g_count&lt;/code&gt; 값에 1을 더하는 같은 연산을 하지만 컨텍스트 스위칭이 언제 일어나는지에 따라 전혀 다른 결과가 나온다. 이처럼 스레드 여러 개가 공유 자원엗 동시에 접근하는 것을 경쟁 조건(race condition)이라고 한다.&lt;/p&gt;

&lt;p&gt;만약 스레드 안에 있는 코드가 공유 자원에 접근해 변경을 시도하는 코드(임계 영역, critical section)가 있으면 문제가 발생한다.&lt;/p&gt;

&lt;h3 id=&quot;24-상호-배제&quot;&gt;2.4 상호 배제&lt;/h3&gt;

&lt;p&gt;경쟁 조건 문제를 해결하기 위해서 상호 배제(mutual exclusion)을 사용한다. 상호 배제의 원리는 간단하며, 스레드 하나가 공유 자원을 이용하는 동안에는 다른 스레드가 접근하지 못하게 막는 것이다. 파이썬에서는 주로 &lt;code class=&quot;highlighter-rouge&quot;&gt;Lock&lt;/code&gt; 객체를 활용한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;threading&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;g_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;thread_main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;global&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g_count&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 한 스레드가 lock을 획득하면&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 획득을 시도한 나머지 스레드는 대기한다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acquire&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;g_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# lock 반환&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 대기하던 스레드 중 하나가 획득&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;release&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
&lt;span class=&quot;n&quot;&gt;lock&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threading&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Lock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;        
&lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threading&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thread_main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'g_count: {:,}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;이제 원하는 대로 결과가 나온다.&lt;/p&gt;</content><author><name>Sunwoong Kim</name></author><category term="python" /><category term="computer science" /><summary type="html">출처: 컴퓨터 사이언스 부트캠프 with 파이썬 (양태환, 길벗)</summary></entry><entry><title type="html">SVM - 이론을 중심으로</title><link href="http://localhost:4000/machinelearning/2018/07/08/SVM-%EC%9D%B4%EB%A1%A0%EC%9D%84-%EC%A4%91%EC%8B%AC%EC%9C%BC%EB%A1%9C/" rel="alternate" type="text/html" title="SVM - 이론을 중심으로" /><published>2018-07-09T08:48:24+09:00</published><updated>2018-07-09T08:48:24+09:00</updated><id>http://localhost:4000/machinelearning/2018/07/08/SVM-%EC%9D%B4%EB%A1%A0%EC%9D%84-%EC%A4%91%EC%8B%AC%EC%9C%BC%EB%A1%9C</id><content type="html" xml:base="http://localhost:4000/machinelearning/2018/07/08/SVM-%EC%9D%B4%EB%A1%A0%EC%9D%84-%EC%A4%91%EC%8B%AC%EC%9C%BC%EB%A1%9C/">&lt;h2 id=&quot;서포트-벡터와-마진&quot;&gt;서포트 벡터와 마진&lt;/h2&gt;

&lt;p&gt;선형 SVM 분류 모델은 판별 함수 $w^T \cdot x - w_0 = w_1x_1 + \cdots w_nx_n - w_0$ 를 계산해서 새로운 샘플 $x$ 의 클래스를 예측한다. $y$ 데이터는 $+1, -1$ 두 개의 값을 가지고, 이를 분류하는 문제를 풀어야 한다. 판별 함수의 정의에 따라 $y$ 값이 $+1$ 인 데이터 $x_+$ 에 대한 판별 함수 값은 양수가 되며, 반대로 $y$ 값이 $-1$ 인 데이터 $x_-$ 에 대한 판별 함수 값은 음수가 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x_+) = w^T \cdot x - w_0 \ge 0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x_-) = w^T \cdot x - w_0 \lt 0&lt;/script&gt;

&lt;p&gt;$y$ 값이 $+1$ 인 데이터 중에서 판별 함수의 값이 가장 작은 데이터를 $x^+$ 라 하고 $y$ 값이 $-1$ 인 데이터 중에서 판별 함수의 값이 가장 큰 데이터를 $x^-$ 라고 하면, 이 데이터들은 각각의 클래스에 속한 데이터 중에서 가장 경계선에 가까이 있는 데이터이다. 이 데이터를 &lt;strong&gt;서포트 벡터 (support vector)&lt;/strong&gt; 라고 한다.&lt;/p&gt;

&lt;p&gt;부호만 지키면 되므로 실제 $f(x^+)$ 와 $f(x^-)$ 값은 어떤 값이 되어도 상관없으므로 다음과 같이 가정한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x_+) = w^T \cdot x - w_0 = 1&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x_-) = w^T \cdot x - w_0 = -1&lt;/script&gt;

&lt;p&gt;판별 경계선과 데이터 $x^+$, $x^-$ 사이의 거리는 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{w^T x^+ - w_0}{\| w \|} = \dfrac{1}{\|w \|}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;-\dfrac{w^T x^- - w_0}{\| w \|} = \dfrac{1}{\| w \|}&lt;/script&gt;

&lt;p&gt;이 거리의 합을 &lt;strong&gt;마진 (margin)&lt;/strong&gt; 이라고 하며 마진이 클 수로 경계선이 더 안정적이라고 할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{w^T x^+ - w_0}{\| w \|} - -\dfrac{w^T x^- - w_0}{\| w \|} = \dfrac{2}{\| w \|}&lt;/script&gt;

&lt;p&gt;마진이 최대가 되는 경우는 $| w |$, 즉 $| w |^2$ 가 최솟값인 경우와 같다. 즉, 다음과 같은 목적 함수를 최소화한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L  = \dfrac{1}{2} \| w \|^2 = \dfrac{1}{2} w^T w&lt;/script&gt;

&lt;blockquote&gt;
  &lt;p&gt;$| w |$ 를 최소화하는 대신 $\dfrac{1}{2} | w |^2$ 인 $\dfrac{1}{2} w^T w$ 를 최소화한다. 이는 $\dfrac{1}{2} w^T$ 가 깔끔하고 간단하게 미분되기 때문이다. 반면 $| w |$ 는 $w = 0$ 에서 미분할 수 없다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;또한 모든 표본 데이터를 제대로 분류해야 하므로 모든 데이터에 대해 다음 조건을 만족해야 한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_i \cdot f(x_i) = y_i \cdot (w^T x_i - w_0) \ge 1 \;\;\; (i = 1, 2, \cdots, ㅜ)&lt;/script&gt;

&lt;p&gt;라그랑주 승수법을 사용하면 목적 함수를 다음과 같이 나타낼 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L = \dfrac{1}{2}w^T w - \sum_{i=1}^N a_i \{ y_i \cdot (w^T x_i - w_0) - 1 \}&lt;/script&gt;

&lt;h2 id=&quot;dual-problem-쌍대-문제-dual-form&quot;&gt;Dual Problem (쌍대 문제, Dual Form)&lt;/h2&gt;

&lt;p&gt;원 문제 (primal problem) 라는 제약이 있는 최적화 문제가 주어지면 &lt;strong&gt;쌍대 문제 (dual problem)&lt;/strong&gt; 라는 다른 문제로 표현할 수 있다. 일반적으로 쌍대 문제 해는 원 문제 해의 하한값이지만, 어떤 조건 하에서는 원 문제와 동일한 해를 제공한다. SVM은 이 조건을 만족시킨다.&lt;/p&gt;

&lt;p&gt;최적화 조건은 목적 함수 $L$ 을 $w$, $w_0$ 으로 미분한 값이 0이 되어야 하는 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{\partial L}{\partial w} = 0​&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{\partial L}{\partial w_0} = 0&lt;/script&gt;

&lt;p&gt;이 식을 풀어서 정리하면 다음과 같아진다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{eqnarray}\dfrac{\partial L}{\partial w} &amp;=&amp; \dfrac{\partial}{\partial w} \left( \dfrac{1}{2} w^T w \right) -     \dfrac{\partial}{\partial w} \sum_{i=1}^N \left( a_i y_i w^Tx_i - a_i y_i w_o - a_i \right) \\\ &amp;=&amp; w - \sum_{i=1}^N  a_i y_i x_i \\\ &amp;=&amp; 0\end{eqnarray} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{eqnarray}\dfrac{\partial L}{\partial w_0} &amp;=&amp; \dfrac{\partial}{\partial w_0} \left( \dfrac{1}{2} w^T w \right) -     \dfrac{\partial}{\partial w_0} \sum_{i=1}^N \left( a_i y_i w^Tx_i - a_i y_i w_o - a_i \right) \\\ &amp;=&amp; \sum_{i=1}^N  a_i y_i \\\ &amp;=&amp; 0\end{eqnarray} %]]&gt;&lt;/script&gt;

&lt;p&gt;즉 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w = \sum_{i=1}^N a_i y_i x_i&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0 = \sum_{i=1}^N a_i y_i&lt;/script&gt;

&lt;p&gt;이 두 수식을 원래의 목적 함수에 대입하여 $w$, $w_0$ 을 없애면 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{eqnarray} L &amp;=&amp; \dfrac{1}{2} w^T w - \sum_{i=1}^N a_i \{ y_i \cdot ( w^Tx_i - w_o) - 1 \}  \\\ &amp;=&amp; \dfrac{1}{2} \left( \sum_{i=1}^N a_i y_i x_i \right)^T \left( \sum_{j=1}^N a_j y_j x_j \right) - \sum_{i=1}^N a_i  \end{eqnarray} %]]&gt;&lt;/script&gt;

&lt;p&gt;정리하면 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L = \sum_{i=1}^N a_i - \dfrac{1}{2}\sum_{i=1}^N\sum_{j=1}^N a_i a_j y_i y_j x_i^T x_j&lt;/script&gt;

&lt;p&gt;이 때 $a$ 는 다음 조건을 만족한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^N a_i y_i = 0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a_i \ge 0 \;\;\; (i = 1, \cdots, N)&lt;/script&gt;

&lt;p&gt;이 식을 최소화하는 $a$ 를 찾으면 예측 모형을 다음과 같이 나타낼 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x) = w^T x - w_0 = \sum_{i=1}^N a_i y_i x_i^T x - w_0&lt;/script&gt;</content><author><name>Sunwoong Kim</name></author><category term="[&quot;MachineLearning&quot;]" /><category term="machine learning" /><summary type="html">서포트 벡터와 마진</summary></entry><entry><title type="html">KKT (Karush-Kuhn-Tucker) 조건</title><link href="http://localhost:4000/machinelearning/2018/07/08/KKT-Karush-Kuhn-Tucker-%EC%A1%B0%EA%B1%B4/" rel="alternate" type="text/html" title="KKT (Karush-Kuhn-Tucker) 조건" /><published>2018-07-08T00:00:00+09:00</published><updated>2018-07-08T00:00:00+09:00</updated><id>http://localhost:4000/machinelearning/2018/07/08/KKT-Karush-Kuhn-Tucker-%EC%A1%B0%EA%B1%B4</id><content type="html" xml:base="http://localhost:4000/machinelearning/2018/07/08/KKT-Karush-Kuhn-Tucker-%EC%A1%B0%EA%B1%B4/">&lt;h2 id=&quot;라그랑주-승수법-lagrange-multiplier&quot;&gt;라그랑주 승수법 (Lagrange Multiplier)&lt;/h2&gt;

&lt;p&gt;등식 제한 조건이 있는 최적화 문제는 라그랑주 승수법을 사용해 최적화할 수 있다. 라그랑주 승수법에서는 $f(x)$ 가 아닌&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h(x, \lambda) = f(x) + \sum_{j=1}^M\lambda_j g_j(x)&lt;/script&gt;

&lt;p&gt;라는 함수를 목적함수로 보고 최적화한다. $h$ 는 독립 변수 $\lambda$ 가 추가되었으므로 다음 조건을 만족해야 한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{eqnarray}\dfrac{\partial h(x, \lambda)}{\partial x_1} &amp;=&amp; \dfrac{\partial f}{\partial x_1} + \sum_{j=1}^M \lambda_j\dfrac{\partial g_j}{\partial x_1} = 0 \\\ \dfrac{\partial h(x, \lambda)}{\partial x_2} &amp;=&amp; \dfrac{\partial f}{\partial x_2} + \sum_{j=1}^M \lambda_j\dfrac{\partial g_j}{\partial x_2} = 0 \\\ \vdots &amp;&amp; \\\ \dfrac{\partial h(x, \lambda)}{\partial x_N} &amp;=&amp; \dfrac{\partial f}{\partial x_N} + \sum_{j=1}^M \lambda_j\dfrac{\partial g_j}{\partial x_N} = 0 \\\ \dfrac{\partial h(x, \lambda)}{\partial \lambda_1} &amp;=&amp; g_1 = 0 \\\ \vdots &amp; &amp; \\\ \dfrac{\partial h(x, \lambda)}{\partial \lambda_M} &amp;=&amp; g_M = 0 \end{eqnarray} %]]&gt;&lt;/script&gt;

&lt;p&gt;위의 $N+M$ 개의 연립방정식을 풀면 $N+M$ 개의 미지수 $x_1, x_2, \ldots, x_N, , \lambda_1, \ldots , \lambda_M$ 를 구할 수 있는데, 여기에서 $x_1, x_2, \cdots, x_N$ 이 제한 조건을 만족하는 최솟값 위치를 나타낸다.&lt;/p&gt;

&lt;h2 id=&quot;kkt-조건&quot;&gt;KKT 조건&lt;/h2&gt;

&lt;p&gt;$g(x) \le 0$ 이라는 부등식 제한 조건이 있는 최적화 문제에서도 마찬가지로 라그랑주 승수법과 마찬가지로&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h(x, \lambda) = f(x) + \sum_{j=1}^M\lambda_j g_j(x)&lt;/script&gt;

&lt;p&gt;를 목적함수로 보고 최적화한다.&lt;/p&gt;

&lt;p&gt;단, 이 경우 최적화 필요 조건은 등식 제한 조건의 경우와는 달리 KKT(Karush-Kuhn-Tucker) 조건으로 부르며, 다음의 3개의 조건으로 이루어진다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모든 독립 변수에 대한 미분이 0: $\dfrac{\partial h(x, \lambda)}{\partial x_i} = 0$&lt;/li&gt;
  &lt;li&gt;모든 라그랑주 승수와 부등식의 곱이 0: $\lambda_j \cdot \dfrac{\partial h(x, \lambda)}{\partial \lambda_j} = \lambda \cdot g_j = 0$&lt;/li&gt;
  &lt;li&gt;음수가 아닌 라그랑주 승수: $\lambda_j \ge 0$&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Sunwoong Kim</name></author><category term="[&quot;MachineLearning&quot;]" /><category term="python" /><category term="machine learning" /><summary type="html">라그랑주 승수법 (Lagrange Multiplier)</summary></entry><entry><title type="html">Loss Function and Gradient</title><link href="http://localhost:4000/machinelearning/2018/07/04/Loss-Function-and-Gradient/" rel="alternate" type="text/html" title="Loss Function and Gradient" /><published>2018-07-05T00:34:45+09:00</published><updated>2018-07-05T00:34:45+09:00</updated><id>http://localhost:4000/machinelearning/2018/07/04/Loss-Function-and-Gradient</id><content type="html" xml:base="http://localhost:4000/machinelearning/2018/07/04/Loss-Function-and-Gradient/">&lt;blockquote&gt;
  &lt;p&gt;그 동안 loss function과 gradient를 공부한 뒤 수학적 의미를 자세히 복습하지 않아서 다시 해당 내용을 복습!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;최적화-문제와-loss-function&quot;&gt;최적화 문제와 Loss Function&lt;/h2&gt;

&lt;p&gt;최적화 문제는 모수를 입력으로, 예측 오차를 출력으로 하는 함수 $f$ 의 값을 최소화하는 $x$ 의 값 $x^{\ast}$ 를 찾는 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x^{\ast} = \arg \underset{x}{\min} f(x)&lt;/script&gt;

&lt;p&gt;이 때 최소화 하려는 함수를 Objective/Cost/Loss Function 등으로 부른다.&lt;/p&gt;

&lt;h2 id=&quot;수치적-최적화-numerical-optimation&quot;&gt;수치적 최적화 (Numerical Optimation)&lt;/h2&gt;

&lt;p&gt;반복적 시행 착오로 최적화 필요조건을 만족하는 $x^{\ast}$ 를 찾는 방법을 수치적 최적화라고 한다. 수치적 최적화는 함수 위치가 최적점이 될 때까지 가능한한 적은 횟수만큼 $x$ 의 위치를 옮기는 방법이다. 이는 두 가지로 구성된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;현재 위치 $x_k$ 가 최적점인지 판단하는 알고리즘&lt;/li&gt;
  &lt;li&gt;어떤 위치를 시도한 뒤, 다음 번에 시도할 위치 $x_{k+1}$ 을 찾는 알고리즘&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;기울기-필요-조건&quot;&gt;기울기 필요 조건&lt;/h3&gt;

&lt;p&gt;현재 시도하고 있는 위치가 최소점인지 알아내기 위해 미분을 이용한다. $x^{\ast}$ 가 최소점이 되기 위해서는 $x^{\ast}$ 에서의 함수의 기울기 $\dfrac{df}{dx}$ 의 값이 0이어야 한다. 이를 기울기 필요 조건이라 한다.&lt;/p&gt;

&lt;p&gt;즉,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\nabla f = \begin{bmatrix}\dfrac{\partial f}{\partial x_1} \\\ \dfrac{\partial f}{\partial x_2} \\\ \vdots \\\ \dfrac{\partial f}{\partial x_n} \end{bmatrix} = 0&lt;/script&gt;

&lt;p&gt;을 만족해야 한다.&lt;/p&gt;

&lt;p&gt;이 때 함수 $f$ 의 &lt;strong&gt;편미분 값을 그래디언트(Gradient)&lt;/strong&gt; 라고 한다.&lt;/p&gt;

&lt;h3 id=&quot;sgd-steepest-gradient-descent&quot;&gt;SGD (Steepest Gradient Descent)&lt;/h3&gt;

&lt;p&gt;SGD 방법은 현재 위치에서의 기울기 $g(x_k)$ 만을 이용해 다음에 시도할 위치를 알아내는 방법이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_{k+1} = x_k - \mu \nabla f(x_k) = x_k - \mu g(x_k)&lt;/script&gt;

&lt;p&gt;현재 위치 $x_k$ 에서 기울기가 음수이면 앞으로 진행하고, 양수이면 뒤로 진행해 점점 낮은 위치로 이동한다. $g(x_k) = 0$ 이면 최소점에 도달한 것이므로 더 이상 위치를 옮기지 않는다.&lt;/p&gt;

&lt;p&gt;간단히 정리하면 SGD는 현재 위치에서 (initial point) 가장 함수값이 작아지는 방향을 찾아서 (gradient) 이동하는 (next position) 알고리즘이다.&lt;/p&gt;</content><author><name>Sunwoong Kim</name></author><category term="[&quot;MachineLearning&quot;]" /><category term="python" /><category term="machine learning" /><summary type="html">그 동안 loss function과 gradient를 공부한 뒤 수학적 의미를 자세히 복습하지 않아서 다시 해당 내용을 복습!</summary></entry><entry><title type="html">[Review] Searching for Activation Functions</title><link href="http://localhost:4000/deeplearning/2018/07/02/Review-Searching-for-Activation-Functions/" rel="alternate" type="text/html" title="[Review] Searching for Activation Functions" /><published>2018-07-02T10:42:06+09:00</published><updated>2018-07-02T10:42:06+09:00</updated><id>http://localhost:4000/deeplearning/2018/07/02/Review-Searching-for-Activation-Functions</id><content type="html" xml:base="http://localhost:4000/deeplearning/2018/07/02/Review-Searching-for-Activation-Functions/">&lt;blockquote&gt;
  &lt;p&gt;출처: &lt;a href=&quot;https://arxiv.org/pdf/1710.05941.pdf&quot;&gt;Prajit Ramachandran, Barret Zoph, Quoc V. Le, Searching for Activation Functions, 2017&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;introductin&quot;&gt;Introductin&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ReLU는 그 간편함에 시그모이드나 tanh보다 더 널리, 딥러닝 커뮤니티에서 각광받는 활성화 함수가 되었음&lt;/li&gt;
  &lt;li&gt;Maas et al., 2013; He et al., 2015; Clevert et al., 2015; Klambauer et al., 2017 등이 ReLU를 대체할 활성화 함수를 제안했지만 ReLU만큼 널리 채택되진 않았음. 많은 이들이 ReLU의 간편함과 안정성을 선호했는데 이는 다른 활성화 함수들은 다른 모델과 데이터셋에서 불안정한 모습을 보였기 때문임&lt;/li&gt;
  &lt;li&gt;ReLU를 대체할 활성화 함수들은 사람의 손으로 설계되었음. 그러나 Zoph &amp;amp; Le, 2016; Bello et al., 2017; Zoph et al., 2017 등의 연구는 사람이 설계하던 부분을 자동화하는 검색 기술이 매우 효과적임을 보임. 특히 Zoph et al., 2017는 convolutional cell을 찾기 위해 강화학습 기반의 검색 기술을 사용했는데 ImageNet에서 사람이 설계한 아키텍처보다 더 높은 성능을 보임&lt;/li&gt;
  &lt;li&gt;본 논문에서는 새로운 활성화 함수를 찾기 위해 자동화 검색 기술을 사용했음. 특히 아키텍처를 변경하지 않으면서도 ReLU를 대체할 수 있는 스칼라 함수를 찾는데 중점을 두었음. (입력과 출력이 모두 스칼라) 철저한 검색과 강화학습 기반의 검색으로  유망한 여러 새로운 활성화 함수를 찾아냄.&lt;/li&gt;
  &lt;li&gt;실증적 평가를 거쳐 찾아낸 함수는 Swish로, 기존 시그모이드에 x 대신 beta・x를 입력으로 주며, 그 시그모이드값에 x를 곱한 형태이다. 베타는 상수 혹은 훈련 가능한 파라미터이다. ReLU를 Swish로 교체한 결과 ImageNet top-1 분류에서 Mobile NASNet-A은 0.9%, Inception-ResNet-v2은 0.6% 만큼 성능이 향상되었음. 이는 꽤 대단한데 Inception V3 (2016)에서 Inception-ResNet-v2 (2017)로 1.3% 성능 향상을 위해 일 년간 파라미터 튜닝을 거쳤기 때문&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;methods&quot;&gt;Methods&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;검색 공간을 설계하는 데 있어 그 크기와 표현성의 밸런스가 필요&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;활성화 함수는 여러 core unit(이항 함수)의 반복으로 구성되었음&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://i.imgur.com/fugNjYJ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;큰 검색 공간에는 RNN 컨트롤러를 사용함 (Zoph &amp;amp; Le, 2016). 각 타임 스텝마다 컨트롤러는 활성화 함수의 한 요소를 예측.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;RNN 컨트롤러는 검증 정확도를 최대화하기 위해 강화학습으로 훈련됨. 이는 RNN 컨트롤러가 가장 높은 검증 정확도를 내는 활성화 함수를 만들어내도록 유도&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/novdov/paper-read/blob/master/img/swish_02.png?raw=true&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;search-findings&quot;&gt;Search Findings&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;찾아진 활성화 함수들은 다음과 같음. 모든 함수는 ResNet-20을 child network로 사용하고 CIFAR-10 데이터에 대해 10K 스텝으로 실험되었음&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/novdov/paper-read/blob/master/img/swish_06.png?raw=true&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;좋은 성능을 보인 활성화 함수들은 다음과 같음
    &lt;ul&gt;
      &lt;li&gt;복잡한 함수는 간단한 함수보다 성능이 나쁨&lt;/li&gt;
      &lt;li&gt;좋은 성능을 내는 함수들은 이항 함수에 $x$ 를 그대로 넣는 $b(x, g(x))$ 의 형태. ReLU의 $g(x)$ 는 $g(x)=0$&lt;/li&gt;
      &lt;li&gt;나눗셈을 사용하는 함수들은 대체로 나쁜 성능을 보이는데 분모가 0에 가까우면 출력값이 폭주하기 때문. 나눗셈이 잘 동작할 때는 1) 분모가 0에서 멀거나, 분자 또한 0에 가까워 출력이 1이 될 경우&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/novdov/paper-read/blob/master/img/swish_03.png?raw=true&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;더 견고한 함수를 찾아내기 위해 텐서플로에서 RestNet-164 (RN), Wide ResNet 28-10 (WRN), DenseNet 100-12 (DN) 세 모델을 대상으로 ReLU를 해당 함수로 대체하는 실험을 진행함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/novdov/paper-read/blob/master/img/swish_04.png?raw=true&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델의 변경에도 불구하고 8개 중 6개 모델이 성공적인 일반화 성능을 보임. $x \cdot \sigma (\beta x)$와 $\max(x, \sigma(x))$가 세 모델에서 모두 ReLU보다 높은 성능을 보임&lt;/li&gt;
  &lt;li&gt;더 좋은 일반화 성능을 보인 $x \cdot \sigma (\beta x)$, Swish 함수에 대해 ReLU와 비교하며 추가적인 평가를 진행함.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;swish&quot;&gt;Swish&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/novdov/paper-read/blob/master/img/swish_05.png?raw=true&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Swish는 $\beta$ 가 0이면 스케일된 선형 ($x/2$) 이고 무한대로 갈수록 0-1 함수, 즉 ReLU에 가까워짐. $\beta$ 를 조절함으로써 선형과 ReLU 사이의 비선형 정도를 조절할 수 있음&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ReLU와 마찬가지로 Swish또한 상하한선이 있음. 반면 ReLU와는 달리 좀 더 부드러우며, 단조롭지 않음. 이 점이 Swish가 다른 활성화 함수와 구별되는 점&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ReLU와 Swish의 가장 큰 차이점인 입력값 $x$ 가 음수일 경우의 “bump”임.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;더군다나 대부분의 딥러닝 라이브러리에서 Swish는 코드 한줄로 바로 실행할 수 있음 (&lt;code class=&quot;highlighter-rouge&quot;&gt;x * tf.sigmoid(beta * x) &lt;/code&gt;  혹은 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.nn.swish(x)&lt;/code&gt;). 또한 ReLU 사용시보다 learning rate를 약간 낮추는 편이 잘 동작했음&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiments-with-swish&quot;&gt;Experiments with Swish&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ResNet-v2나 Transformer 등의 모델로 Swish와 여러 활성화 함수를 비교함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/mfbqCwv.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Swish는 간단하며 ReLU와 비슷한데, 이는 네트워크에서 ReLU를 교체하는 것은 코드 한 줄이면 된다는 것을 의미&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Sunwoong Kim</name></author><category term="deep learning" /><category term="review" /><summary type="html">출처: Prajit Ramachandran, Barret Zoph, Quoc V. Le, Searching for Activation Functions, 2017</summary></entry><entry><title type="html">Batch Normalization</title><link href="http://localhost:4000/deeplearning/2018/05/29/Batch-Normalization/" rel="alternate" type="text/html" title="Batch Normalization" /><published>2018-05-30T07:33:21+09:00</published><updated>2018-05-30T07:33:21+09:00</updated><id>http://localhost:4000/deeplearning/2018/05/29/Batch-Normalization</id><content type="html" xml:base="http://localhost:4000/deeplearning/2018/05/29/Batch-Normalization/">&lt;blockquote&gt;
  &lt;p&gt;참고: 밑바닥부터 시작하는 딥러닝 (사이토 고키 저, 개앞맵시 역, 한빛미디어)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;배치 정규화는 2015년 &lt;a href=&quot;https://arxiv.org/pdf/1502.03167.pdf&quot;&gt;Sergey Ioffe, Christian Szegedy&lt;/a&gt;가 제안한 방법이다. 배치 정규화는 널리 사용되는 방법인데 그 이유는 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;학습을 빨리 진행할 수 있다.&lt;/li&gt;
  &lt;li&gt;초깃값에 크게 의존하지 않는다.&lt;/li&gt;
  &lt;li&gt;과대적합을 억제한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;배치 정규화의 기본 아이디어는 각 층에서의 활성화값이 적당히 분포되도록 조정하는 것이다. 학습 시 미니배치 단위로 정규화하는데 구체적으로는 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_B \leftarrow \dfrac{1}{m}\sum_{i=1}^m x_i&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma_B^2 \leftarrow \dfrac{1}{m}\sum_{i=1}^m (x_i - \mu_B)^2&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x}_i \leftarrow \dfrac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}&lt;/script&gt;

&lt;p&gt;여기에는 미니배치 $B = { x_1, x_2, \cdots, x_m }$ 이라는 $m$ 개의 입력 데이터의 집합에 대해 평균 $\mu_B$ 와 분산 $\sigma_B^2$ 를 구한다. 그리고 입력 데이터를 평균이 0, 분산이 1인 데이터 ${ \hat{x}_1, \hat{x}_2, \cdots, \hat{x}_m }$ 가 되도록 정규화한다.&lt;/p&gt;

&lt;p&gt;또 배치 정규화 계층마다 이 정규화된 데이터에 고유한 확대(scale)와 이동(shift) 변환을 수행한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_i = \gamma \hat{x}_i + \beta&lt;/script&gt;

&lt;p&gt;위 식에서 $\gamma$ 가 확대를, $\beta$ 가 이동을 담당한다. 두 값은 $\gamma = 1$, $\beta = 0$ 부터 시작한다. (1배 확대 및 0 이동 즉, 원본 그대로에서 시작)&lt;/p&gt;</content><author><name>Sunwoong Kim</name></author><category term="deep learning" /><summary type="html">참고: 밑바닥부터 시작하는 딥러닝 (사이토 고키 저, 개앞맵시 역, 한빛미디어)</summary></entry></feed>