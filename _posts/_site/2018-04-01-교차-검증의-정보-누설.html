<blockquote>
  <p>The Elements of Statistical Learning (Hastie, Springer, 2016)</p>

  <p>파이썬 라이브러리를 활용한 머신러닝 (안드레아스 뮐러 저, 박해선 역, 한빛미디어, 2017)</p>
</blockquote>

<h3 id="improper-preprocessing">Improper Preprocessing</h3>

<p>교차 검증에서 검증 폴드 데이터의 정보가 모델 구축 과정에 누설되면 교차 검증에서 낙관적인 결과가 만들어진다. 아래 그림에서는 파라미터 선택을 위해 <code class="highlighter-rouge">scaler.fit</code>과 <code class="highlighter-rouge">SVC.predict</code>가 모두 검증 폴드를 사용하고 있다. 하지만 모델의 성능을 평가할 때는 <code class="highlighter-rouge">scaler.fit</code>이 테스트 세트에 적용되지 않는다. (아래와 같은 문제를 해결하기 위해 Pipeline을 사용한다.)</p>

<p><img src="https://github.com/novdov/study/blob/master/img/improper.png?raw=true" alt="mage-20180401155447" /></p>

<p><strong>[Pipeline 사용 예시]</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># MinMaxScaler와 SVC를 Pipeline으로 연결하고</span>
<span class="c"># GridSearchCV에 Pipeline을 적용</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">"Scaler"</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">()),</span> <span class="p">(</span><span class="s">"svm"</span><span class="p">,</span> <span class="n">SVC</span><span class="p">())])</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s">"svm__C"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> 
              <span class="s">"svm__gamma"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="교차-검증에서-정보-누설의-영향">교차 검증에서 정보 누설의 영향</h3>

<p>무작위로 생성된 X와 y에는 아무런 관계가 없다. (독립)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 정규분포로부터 독립적으로 추출한 10,000개의 특성을 가진 샘플 100개</span>

<span class="n">rnd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">rnd</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">rnd</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,))</span>
</code></pre></div></div>

<p>아래와 같이 피처를 선택하고 학습을 시키면 다음과 같은 점수를 얻는다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># SelectPercentile로 유용한 피처를 선택하고 교차 검증을 사용해 Ridge 회귀 평가</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectPercentile</span><span class="p">,</span> <span class="n">f_regression</span>

<span class="n">select</span> <span class="o">=</span> <span class="n">SelectPercentile</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">f_regression</span><span class="p">,</span> <span class="n">percentile</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_selected</span> <span class="o">=</span> <span class="n">select</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"X_selected.shape: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_selected</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="c"># (100, 500)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="k">print</span><span class="p">(</span><span class="s">"CV Score (Ridge): {:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">Ridge</span><span class="p">(),</span> <span class="n">X_selected</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">))))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">CV</span> <span class="n">Score</span> <span class="p">(</span><span class="n">Ridge</span><span class="p">):</span> <span class="mf">0.91</span>
</code></pre></div></div>

<p>$R^2​$가 0.91로 매우 좋은 모델이라고 생각할 수 있지만, 데이터셋을 무작위로 만들었기 때문에 불가능한 일이다. 교차 검증 밖에서 특성을 선택했기 때문에 훈련과 테스트 폴드 양쪽에 연관된 특성이 찾아질 수 있다. 테스트 폴드에서 유출된 정보는 매우 중요한 역할을 하기 때문에 비현실적으로 높은 결과가 나왔다. 이 결과를 Pipeline을 이용한 교차 검증과 비교하면 다음과 같다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">"select"</span><span class="p">,</span> <span class="n">SelectPercentile</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">f_regression</span><span class="p">,</span> 
                                             <span class="n">percentile</span><span class="o">=</span><span class="mi">5</span><span class="p">)),</span> 
                 <span class="p">(</span><span class="s">"ridge"</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">())])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"CV score (Pipeline): {:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">))))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">CV</span> <span class="n">score</span> <span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span> <span class="o">-</span><span class="mf">0.25</span>
</code></pre></div></div>

<p>이번에는 $R^2$가 음수로 성능이 매우 나쁘 모델임을 나타낸다. Pipeline을 사용했기 때문에 특성 선택이 교차 검증 반복 안으로 들어갔다. 즉, 훈련 폴드를 사용해서만 특성이 선택되었고 테스트 폴드는 사용되지 않았다는 뜻이다. 특성 선택 단계에서 타깃값과 연관된 훈련 폴드의 특성을 찾았지만 전체 데이터가 무작위로 만들어졌으므로 테스트 폴드의 타깃과는 연관성이 없다. 이는 특성 선택 단계에서 일어나는 정보 누설을 막는 것이 모델의 성능을 평가하는 데 큰 차이를 만든다는 것을 보여준다.</p>

